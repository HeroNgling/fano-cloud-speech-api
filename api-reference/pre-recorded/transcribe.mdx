---
title: 'Transcribe Audio'
description: 'Transcribe pre-recorded audio files'
api: 'POST /transcribe'
---

# Transcribe Audio

Transcribe pre-recorded audio files to text.

## Endpoint

```
POST https://api.fano.ai/v1/transcribe
```

## Request

### Headers

<ParamField header="Authorization" type="string" required>
  Bearer token with your API key.
  
  Example: `Bearer sk_live_abc123...`
</ParamField>

<ParamField header="Content-Type" type="string" required>
  Either `application/json` for URL-based requests or the audio MIME type for direct upload.
</ParamField>

### Body Parameters

<ParamField body="audio_url" type="string">
  URL of the audio file to transcribe. Required if not uploading audio directly.
</ParamField>

<ParamField body="audio_data" type="string">
  Base64-encoded audio data. Required if not providing `audio_url`.
</ParamField>

<ParamField body="language" type="string" default="auto">
  Language code for the audio. Use `auto` for automatic detection.
  
  Options: `en`, `zh-HK`, `zh-CN`, `ms`, `id`, `th`, `vi`, `fr`, `ar`, `auto`
</ParamField>

<ParamField body="model" type="string" default="general">
  Speech recognition model to use.
  
  Options: `general`, `telephony`, `meeting`, `broadcast`
</ParamField>

<ParamField body="punctuation" type="boolean" default="true">
  Enable automatic punctuation.
</ParamField>

<ParamField body="capitalize" type="boolean" default="true">
  Enable automatic capitalization.
</ParamField>

<ParamField body="diarization" type="boolean" default="false">
  Enable speaker diarization.
</ParamField>

<ParamField body="max_speakers" type="integer" default="2">
  Maximum number of speakers to identify (when diarization is enabled).
  
  Range: 1-8
</ParamField>

<ParamField body="keywords" type="array">
  List of keywords to boost recognition accuracy.
</ParamField>

<ParamField body="keyword_boost" type="number" default="1.5">
  Strength of keyword boosting.
  
  Range: 1.0-3.0
</ParamField>

<ParamField body="word_timestamps" type="boolean" default="false">
  Include word-level timestamps in the response.
</ParamField>

<ParamField body="callback_url" type="string">
  Webhook URL to receive results for async processing.
</ParamField>

## Response

<ResponseField name="success" type="boolean">
  Whether the request was successful.
</ResponseField>

<ResponseField name="data" type="object">
  <Expandable title="properties">
    <ResponseField name="transcript" type="string">
      The full transcript text.
    </ResponseField>
    
    <ResponseField name="confidence" type="number">
      Overall confidence score (0-1).
    </ResponseField>
    
    <ResponseField name="duration" type="number">
      Audio duration in seconds.
    </ResponseField>
    
    <ResponseField name="detected_language" type="string">
      Detected language code (when `language: auto`).
    </ResponseField>
    
    <ResponseField name="words" type="array">
      Word-level details (when `word_timestamps: true`).
      
      <Expandable title="word object">
        <ResponseField name="word" type="string">
          The transcribed word.
        </ResponseField>
        <ResponseField name="start" type="number">
          Start time in seconds.
        </ResponseField>
        <ResponseField name="end" type="number">
          End time in seconds.
        </ResponseField>
        <ResponseField name="confidence" type="number">
          Word confidence score.
        </ResponseField>
      </Expandable>
    </ResponseField>
    
    <ResponseField name="speakers" type="array">
      Speaker segments (when `diarization: true`).
      
      <Expandable title="speaker object">
        <ResponseField name="speaker_id" type="integer">
          Speaker identifier.
        </ResponseField>
        <ResponseField name="start" type="number">
          Segment start time.
        </ResponseField>
        <ResponseField name="end" type="number">
          Segment end time.
        </ResponseField>
        <ResponseField name="text" type="string">
          Transcript for this segment.
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="metadata" type="object">
  <Expandable title="properties">
    <ResponseField name="request_id" type="string">
      Unique request identifier.
    </ResponseField>
    <ResponseField name="processing_time_ms" type="integer">
      Processing time in milliseconds.
    </ResponseField>
  </Expandable>
</ResponseField>

## Examples

<CodeGroup>

```python Python
import requests

API_KEY = "your_api_key_here"

response = requests.post(
    "https://api.fano.ai/v1/transcribe",
    headers={
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    },
    json={
        "audio_url": "https://example.com/audio.wav",
        "language": "auto",
        "punctuation": True,
        "diarization": True,
        "max_speakers": 3,
        "word_timestamps": True
    }
)

result = response.json()
print(result["data"]["transcript"])
```

```javascript JavaScript
const response = await fetch('https://api.fano.ai/v1/transcribe', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer your_api_key_here',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    audio_url: 'https://example.com/audio.wav',
    language: 'auto',
    punctuation: true,
    diarization: true,
    max_speakers: 3,
    word_timestamps: true
  })
});

const result = await response.json();
console.log(result.data.transcript);
```

```bash cURL
curl -X POST "https://api.fano.ai/v1/transcribe" \
  -H "Authorization: Bearer your_api_key_here" \
  -H "Content-Type: application/json" \
  -d '{
    "audio_url": "https://example.com/audio.wav",
    "language": "auto",
    "punctuation": true,
    "diarization": true,
    "max_speakers": 3,
    "word_timestamps": true
  }'
```

</CodeGroup>

### Success Response

```json
{
  "success": true,
  "data": {
    "transcript": "Hello, this is speaker one. And this is speaker two responding.",
    "confidence": 0.94,
    "duration": 5.2,
    "detected_language": "en",
    "words": [
      {"word": "Hello", "start": 0.0, "end": 0.5, "confidence": 0.98},
      {"word": "this", "start": 0.6, "end": 0.8, "confidence": 0.96},
      {"word": "is", "start": 0.9, "end": 1.0, "confidence": 0.97}
    ],
    "speakers": [
      {"speaker_id": 1, "start": 0.0, "end": 2.5, "text": "Hello, this is speaker one."},
      {"speaker_id": 2, "start": 2.6, "end": 5.2, "text": "And this is speaker two responding."}
    ]
  },
  "metadata": {
    "request_id": "req_abc123xyz",
    "processing_time_ms": 1234
  }
}
```

### Error Response

```json
{
  "success": false,
  "error": {
    "code": "INVALID_AUDIO_FORMAT",
    "message": "The provided audio format is not supported",
    "details": {
      "provided_format": "aac",
      "supported_formats": ["wav", "mp3", "flac", "ogg", "webm"]
    }
  }
}
```

## Error Codes

| Code | Description |
|------|-------------|
| `INVALID_AUDIO_FORMAT` | Unsupported audio format |
| `AUDIO_TOO_LONG` | Audio exceeds maximum duration |
| `AUDIO_DOWNLOAD_FAILED` | Failed to download audio from URL |
| `PROCESSING_ERROR` | Internal processing error |
