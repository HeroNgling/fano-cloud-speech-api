openapi: 3.1.0
info:
  title: Fano Speech API - Streaming Transcription
  description: |
    Real-time speech recognition using WebSocket connection for live audio streams and conversational applications.
    
    ## Connection Protocol
    
    This API uses **Secure WebSockets (WSS)** for streaming. The connection flow is:
    
    1. **Connect** - Establish WebSocket connection with authentication
    2. **Configure** - Send configuration message
    3. **Stream** - Send audio chunks, receive transcription results
    4. **Close** - Send EOF to gracefully terminate
    
    ## Base URL
    
    ```
    wss://app.fano.ai/api/v1/speech-to-text/streaming-transcript
    ```
  version: 1.0.0
  contact:
    name: Fano Labs
    url: https://fano.ai
  license:
    name: Proprietary
    url: https://fano.ai/terms

servers:
  - url: wss://app.fano.ai/api/v1/speech-to-text
    description: Production WebSocket Server

tags:
  - name: Streaming
    description: Real-time streaming transcription operations

paths:
  /streaming-transcript:
    get:
      operationId: streamingTranscript
      summary: Streaming Transcription (WebSocket)
      description: |
        Establish a WebSocket connection for real-time speech-to-text transcription.
        
        **Connection Flow:**
        1. Connect to WebSocket endpoint with authentication header
        2. Send configuration message (Step 1)
        3. Stream audio chunks (Step 2)
        4. Receive real-time results (Step 3)
        5. Send EOF to close connection (Step 4)
        
        **Note:** This is a WebSocket endpoint. Use `wss://` protocol for connection.
      tags:
        - Streaming
      security:
        - FanoLicenseKey: []
      parameters:
        - name: Fano-license-key
          in: header
          required: true
          description: Your unique license key provided by Fano Labs
          schema:
            type: string
            example: "your-api-key-here"
      responses:
        '101':
          description: WebSocket connection established successfully
        '401':
          description: Unauthorized - Invalid or missing API key
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
              example:
                error:
                  code: 401
                  message: "Invalid or missing Fano-license-key"
        '400':
          description: Bad Request - Invalid connection parameters
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'

  /streaming-transcript/configure:
    post:
      operationId: configureStream
      summary: "Step 1: Configure Stream"
      description: |
        Send configuration immediately after WebSocket connection is established.
        This initializes the transcription session with your desired settings.
      tags:
        - Streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ConfigureRequest'
            examples:
              basic:
                summary: Basic Configuration
                value:
                  config:
                    languageCode: "yue"
                    sampleRateHertz: 16000
                    encoding: "LINEAR16"
              withPunctuation:
                summary: With Punctuation & Interim Results
                value:
                  config:
                    languageCode: "yue-x-auto"
                    sampleRateHertz: 16000
                    encoding: "LINEAR16"
                    enableAutomaticPunctuation: true
                    interimResults: true
              withKeywords:
                summary: With Keyword Biasing
                value:
                  config:
                    languageCode: "en"
                    sampleRateHertz: 16000
                    encoding: "LINEAR16"
                    enableAutomaticPunctuation: true
                    interimResults: true
                    speechContexts:
                      keywords:
                        - "Fano"
                        - "transcription"
                        - "speech recognition"
      responses:
        '200':
          description: Configuration accepted
        '400':
          description: Invalid configuration
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
              example:
                error:
                  code: 3
                  message: "invalid languageCode: must be one of yue, cmn, en, yue-x-auto"

  /streaming-transcript/audio:
    post:
      operationId: sendAudioChunk
      summary: "Step 2: Send Audio Chunk"
      description: |
        Send audio data in chunks after configuration. Audio must be Base64 encoded.
        
        **Recommended chunk size:** 100ms - 500ms of audio data
        
        **Audio Requirements:**
        - Encoding: LINEAR16 (PCM 16-bit) or MULAW
        - Channels: Single channel (mono) only
        - Sample Rate: 8000 Hz - 48000 Hz (16000 Hz recommended)
      tags:
        - Streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AudioChunkRequest'
            example:
              audioContent: "UklGRiQAAABXQVZFZm10IBAAAAABAAEAgD4AAAB9..."
      responses:
        '200':
          description: Audio chunk received
        '400':
          description: Invalid audio data
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Error'
              example:
                error:
                  code: 3
                  message: "invalid Base64 encoding in audioContent"

  /streaming-transcript/results:
    get:
      operationId: receiveResults
      summary: "Step 3: Receive Real-time Results"
      description: |
        The server pushes transcription results as audio is processed.
        
        Results include:
        - **Interim results** (`isFinal: false`): Tentative transcriptions that may change
        - **Final results** (`isFinal: true`): Committed transcriptions that won't change
      tags:
        - Streaming
      responses:
        '200':
          description: Transcription result received
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TranscriptionResponse'
              examples:
                interimResult:
                  summary: Interim Result
                  value:
                    results:
                      - alternatives:
                          - transcript: "Hello, how can I"
                            confidence: 0.0
                            startTime: "0.000s"
                            endTime: "1.500s"
                            languageCode: "en"
                        resultEndTime: "1.500s"
                        channelTag: 1
                        isFinal: false
                    metadata:
                      asrModels:
                        - "model_1"
                finalResult:
                  summary: Final Result
                  value:
                    results:
                      - alternatives:
                          - transcript: "Hello, how can I help you today?"
                            confidence: 0.95
                            startTime: "0.000s"
                            endTime: "3.200s"
                            languageCode: "en"
                        resultEndTime: "3.200s"
                        channelTag: 1
                        isFinal: true
                    metadata:
                      asrModels:
                        - "model_1"
                        - "model_2"

  /streaming-transcript/eof:
    post:
      operationId: sendEOF
      summary: "Step 4: Send EOF"
      description: |
        Send EOF (End of File) to gracefully close the streaming session.
        The server will finish processing any remaining audio and close the connection.
      tags:
        - Streaming
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EOFRequest'
            example:
              eof: true
      responses:
        '200':
          description: EOF received, connection closing

components:
  securitySchemes:
    FanoLicenseKey:
      type: apiKey
      in: header
      name: Fano-license-key
      description: Your unique license key provided by Fano Labs

  schemas:
    ConfigureRequest:
      type: object
      required:
        - config
      properties:
        config:
          type: object
          required:
            - languageCode
            - sampleRateHertz
            - encoding
          properties:
            languageCode:
              type: string
              description: |
                The language code for transcription. Follows BCP-47 format.
              enum:
                - yue
                - cmn
                - en
                - yue-x-auto
              example: "yue-x-auto"
            sampleRateHertz:
              type: integer
              description: |
                Sample rate in Hertz of the audio data.
                
                For best results, set to 16000 Hz. If not possible, use the native sample rate of the audio source instead of re-sampling.
              minimum: 8000
              maximum: 48000
              example: 16000
            encoding:
              type: string
              description: |
                The encoding format of the audio data.
                
                All encodings support only 1 channel (mono) audio.
              enum:
                - LINEAR16
                - MULAW
              example: "LINEAR16"
            enableAutomaticPunctuation:
              type: boolean
              description: |
                If `true`, adds punctuation to recognition result hypotheses.
              default: false
              example: true
            interimResults:
              type: boolean
              description: |
                If `true`, interim results (tentative hypotheses) may be returned as they become available. These are indicated with `isFinal=false`.
                
                If `false` or omitted, only `isFinal=true` results are returned.
              default: false
              example: true
            speechContexts:
              type: object
              description: Configuration for keyword biasing features.
              properties:
                keywords:
                  type: array
                  description: |
                    Array of keywords to boost recognition accuracy.
                    
                    **Limit:** Maximum 1000 items per request.
                  items:
                    type: string
                  maxItems: 1000
                  example:
                    - "Fano"
                    - "transcription"
            audioChannelCount:
              type: integer
              description: Number of audio channels (default is 1 for mono).
              default: 1
              minimum: 1
              maximum: 8
            enableSeparateRecognitionPerChannel:
              type: boolean
              description: |
                If `true`, enables separate recognition per audio channel.
                Requires `audioChannelCount` to be set.
              default: false

    AudioChunkRequest:
      type: object
      required:
        - audioContent
      properties:
        audioContent:
          type: string
          format: byte
          description: |
            The audio data bytes, Base64 encoded.
            
            **Recommended chunk size:** 100ms - 500ms of audio data.
          example: "UklGRiQAAABXQVZFZm10IBAAAAABAAEAgD4AAAB9..."

    EOFRequest:
      type: object
      required:
        - eof
      properties:
        eof:
          type: boolean
          description: Set to `true` to gracefully terminate the connection.
          const: true
          example: true

    TranscriptionResponse:
      type: object
      properties:
        results:
          type: array
          description: Array of recognition results.
          items:
            $ref: '#/components/schemas/RecognitionResult'
        metadata:
          type: object
          description: Metadata about the transcription process.
          properties:
            asrModels:
              type: array
              description: List of ASR models used for transcription.
              items:
                type: string
              example:
                - "model_1"
                - "model_2"

    RecognitionResult:
      type: object
      properties:
        alternatives:
          type: array
          description: Array of alternative transcriptions, ordered by confidence.
          items:
            $ref: '#/components/schemas/SpeechRecognitionAlternative'
        resultEndTime:
          type: string
          description: |
            Time offset of the end of this result relative to the beginning of the audio.
            
            Format: seconds with nanosecond precision (e.g., "3.000000001s")
          example: "3.200s"
        channelTag:
          type: integer
          description: Channel identifier for multi-channel audio.
          example: 1
        isFinal:
          type: boolean
          description: |
            - `false`: Interim result that may change
            - `true`: Final result, no further updates for this portion
          example: false

    SpeechRecognitionAlternative:
      type: object
      properties:
        transcript:
          type: string
          description: Transcript text representing the words that the user spoke.
          example: "Hello, how can I help you today?"
        confidence:
          type: number
          format: float
          description: |
            Confidence estimate between 0.0 and 1.0. Higher values indicate greater likelihood of correctness.
            
            **Note:** A value of 0.0 indicates confidence was not set. This field is not guaranteed to be accurate.
          minimum: 0.0
          maximum: 1.0
          example: 0.95
        startTime:
          type: string
          description: |
            Start time of detected audio segment with voice activity.
            
            Format: seconds with millisecond precision (e.g., "0.000s")
          example: "0.000s"
        endTime:
          type: string
          description: |
            End time of detected audio segment with voice activity.
            
            Format: seconds with millisecond precision (e.g., "3.200s")
          example: "3.200s"
        languageCode:
          type: string
          description: Detected language code of the segment (BCP-47 format).
          example: "en"

    Error:
      type: object
      properties:
        error:
          type: object
          properties:
            code:
              type: integer
              description: |
                gRPC status code. See [gRPC Status Codes](https://grpc.github.io/grpc/core/md_doc_statuscodes.html).
              example: 3
            message:
              type: string
              description: Human-readable error message.
              example: "invalid message format"
